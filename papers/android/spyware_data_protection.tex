\section{Spyware User Data Protection}
\label{sec:data-leak}

%\damon{at a high level I need to make it clear that I only attempted to access our own data and I should also include citations to prior news articles and industry reports that overlap with our findings.}

%% \geoff{need to describe the various infrastructure elements involved
%%   (device, accounts, servers) and lifecycle steps (when does the
%%   abuser create/setup/access an account, does the abuser download and
%%   install the spyware on the victim's device after creating an
%%   account, abuser account registration vs victim device registration
%%   to an abuser's account, high-level of how the abuser remotely
%%   controls the spyware on the victim's device).  might also go earlier
%%   in the paper for context on app implementation, but particularly
%%   needed for understanding the data protection part.}
%\sumanth{Not sure where this should go. Here in the intro?} \geoff{yes put it here for now, don't
%  worry about the flow with other parts for now}

In this section I assess how well spyware apps secure the user data they exfiltrate and store.
For this assessment, in addition to the victim and the abuser, we
consider a third actor: an external attacker who seeks to undermine the
security of the spyware app.  The attacker's goal is to exploit any
integrity, authorization, and authentication issues with the spyware
app to access victim data as a third party.
% that the attacker is not supposed to have access to.

%% When discussing each of the security issues below, I note further
%% assumptions about the attacker that are specific to a particular
%% issue.

%% Table~\ref{tab:apps_spyware_vuln} summarizes the threats we
%% investigated and shows which apps are susceptible to them.

We start by describing our
methodology for investigating the data protection practices of the
spyware apps, and then discuss each of the vulnerabilities I uncovered (summarized in Table~\ref{tab:apps_spyware_vuln}).

\subsection{Methodology}
\label{subsec:experiemental_setup}

%\sumanth{Revised methodology section 4.1}
For each app I analyzed, I obtained an account (providing payment
information when necessary) and registered the app on a Pixel 2 XL
Android phone running Android 10.
%% I used man-in-the-middle (MITM) traffic inspection to perform our
%% network analysis on each spyware app.

To identify apps sending data from the device to the backend servers via unencrypted connections I used \texttt{tcpdump},
listening on a Windows 10 machine interface configured as a mobile
hotspot, to capture and inspect app traffic over the network.  We
configured the Android phone to connect to the PC and recorded all
traffic exchanged with the app servers, without any proxy in between
(avoiding any potential TLS handshake failures due to certificate
pinning).

To study the interactions between the spyware web portal interface and
the spyware backend servers, I used the open-source \texttt{MITMProxy} tool to
decrypt HTTPS traffic.  This configuration gave us access to
authentication tokens (session cookies, secrets, etc.) for conducting
forgery attacks on our test accounts.  I were able to login to all
portals without error (e.g., there were no issues with certificate
pinning).  I also analyzed the HTML content displayed via the spyware
web portal interface, extracting the URLs linked to uploaded user
media (images, audio, etc.).  I then performed a sequence of
experiments that tested and verified each insecurity listed in
Table~\ref{tab:apps_spyware_vuln}.

% I installed a trusted PEM certificate (generated
% by the proxy) on the phone, adding the certificate to the list of user
% store certificate authorities.

%% \geoff{could also aggregate the specific methodology parts from the
%%   subsections here}

%% For each app I analyzed, I obtained an account (providing payment information when necessary) and registered the app on a Pixel 2 XL Android phone running Android 10. I used a man-in-the-middle (MITM) traffic inspection approach to perform our network analysis on each spyware app, focusing on outgoing requests from each app that I manually installed on the Android phone. I leveraged the open-source MITMProxy tool to inspect outgoing requests, which I setup and ran on a Windows 10 PC noting its IP address. I then configured the Android phone to connect to a mobile hotspot setup on the PC, and configured a manual proxy to route all traffic to port 8080 - that the traffic inspector actively ran on. In order to decrypt TLS traffic, I installed a trusted PEM certificate (generated by the traffic inspector) on the phone, which adds the certificate to the list of user store certificate authorities. For each spyware app, I installed the mobile app onto the Android phone, logged in using the abusers credentials and ran through the sequence of experiments which test each insecurity listed in table \ref{tab:apps_spyware_vuln}.
%% I also analyzed the spyware web portal interface and extracted the path for uploaded user media (images, audio, etc) which I used for the following experiments.

\subsection{Results}

Table~\ref{tab:apps_spyware_vuln} summarizes the threats we
investigated and shows which apps are susceptible to them.
%
We describe each of the threats in turn, summarizing its context, its
associated threat model, any additional methods I employed, and the
specific results I discovered for the vulnerable apps.

%% I start by briefly describing each insecurity, along with the threat
%% model and experimental setup used to identify the insecurity. I then
%% discuss a subset of the apps which demonstrate each insecurity. To
%% structure our analysis, I focused on security mechanisms for
%% protecting sensitive user data.

%We are less interested in flows that do not aid in compromising the app or user data; for example, apps that are using unsecured HTTP connections for non-sensitive functionality.

%% \geoff{the structure of these subsections results in some redundancy
%%   across the various parts, which is not ideal.  but it does have the
%%   virtue of being explicit about each of the parts.}

%\subsubsection*{Insecurity \#1: Submitting sensitive victim or abuser PII over the network}
\subsubsection*{Insecurity \#1: Eavesdropping Sensitive Personally Identifiable Information (PII)}
%\subsubsection{Eavesdropping sensitive PII}

Some spyware apps transmit highly sensitive victim data, such as photos,
texts, and location, from the victim device to the spyware backend
servers using unencrypted HTTP connections.  A MITM attacker who
eavesdrops on the same communication channel (e.g., same WiFi network)
could collect all data and credentials sent unencrypted
over the network.  Furthermore, credentials leaked over the network enable
an attacker to login to the abuser's account and gain access to all of
the victim's data exfiltrated by the spyware.

\textbf{Threat Model.} I assume that the attacker can eavesdrop on
all messages sent by the mobile device infected with spyware (e.g.,
the attacker uses the same WiFi network as the victim, and the WiFi
network is not using link-layer encryption).

%% I also assume that the network used when eavesdropping is unencrypted
%% (e.g., a WiFi network not using link-layer encryption).

%% \geoff{doesn't the WiFi network need to
%%   be unencrypted (not use link-layer encryption)?} \sumanth{Addressed}

\textbf{Experimental Setup.}
%% To uncover sensitive data flows, I utilized the spyware's
%% functionality and observed the outgoing network traffic from the
%% target device.
We filtered the captured traffic to observe network activity from each app over
insecure channels like HTTP, and used a combination of search and
manual inspection to analyze the recorded traffic for sensitive data
such as leaked credentials (user names, email addresses, passwords),
text messages,
% call logs,
etc.

%% Filter's were setup to flag any network activity over insecure
%% channels like HTTP. These packets were manually analyzed to see if
%% they leaked passwords, messages, call logs, etc. Similarly I flagged
%% packets containing sensitive PII's (i.e., user/abuser email) using
%% regex matching.

%% \damon{did I check for password, sms, call logs, messages?}
%% \sumanth{Added a line above that I analyzed insecure packets to see
%%   if they leaked all these.}

\textbf{Results.}  Four spyware apps in our study leak at least some
of their data using vulnerable communication channels.  TheTruthSpy
submits all of its data over HTTP, and it leaks the abuser's
credentials for TheTruthSpy servers (abuser email address and
password) in the authentication request during app setup.
%% It also leaks the abuser email address
%% in response to an unauthenticated request for registration information.
%% TheTruthSpy also leaks the abuser's email address in the response to
%% an endpoint called during setup time.
%% \geoff{victim's?}
%% \sumanth{Edited to make it clearer. There are 2 cases - email and pwd
%%   leaked in a request during setup time, and just the email leaked in
%%   the response every time a particular endpoint is called}.
%% \geoff{``endpoint'' is still a bit vague? if the email address leak is
%%   also during setup, then I think I can leave it out (the full
%%   credential leak is already a worse case)}
mSPY leaks only
the upload path for its images in an HTTP response back to the
victim's device when the image upload succeeds.
%\sumanth{Added this for Clevguard}
Clevguard uploads its images over HTTP, making it is possible for an attacker to reconstruct the image from the payload.  Flexispy uses
HTTP for all of its communication, but it implements a custom
encryption protocol for the data it sends.  However, a previously
discovered flaw in Flexispy's encryption makes it possible to
intercept personal data sent over the
network~\cite{Stalking85:online}.

%% I observed 3 spyware apps send their data - like texts, images,
%% locations - over plain HTTP protocol. \textbf{TheTruthSpy} submits all
%% its data over HTTP. Further, it leaks both the abuser email and
%% password during app setup time (when authenticating), and the abuser's
%% email during setup time. \textbf{mSpy} on the other hand leaks only
%% the upload path for its images in a HTTP response back to the victim's
%% device once the upload is successful. While both these apps send data
%% in the clear, \textbf{Flexispy} implements a custom encryption
%% protocol even though it sends data over HTTP. However, a perviously
%% discovered flaw in Flexispy's encryption makes it possible to
%% intercept personal data being sent over the network
%% \cite{Stalking85:online}.

\subsubsection*{Insecurity \#2: Cross-account Request Forgery}
%\subsubsection{Cross-account request forgery}

Knowing a particular user identifier, or a file path that provides access to images, audio, or video on the server, an attacker can use valid
cookies from one spyware account to access data or perform actions in
the accounts of other spyware users.

\textbf{Threat Model.} The attacker can register a spyware account and
log into it. Using a MITM traffic inspector (similar to our proxy
described in Section~\ref{subsec:experiemental_setup}), an attacker
can intercept and replay authenticated requests from their account. We
assume the attacker knows the ID of the targeted user's account ---
either through enumeration, or from the ID being leaked over the
network or in a public data dump~\cite{mSpybrea38:online,
  Companyt8:online, HackerSt66:online, Cerberus12:online,
  Stalkerw59:online}.

%% \damon{this is cryptic, I would suggest directly stating that the
%%   attacker can register/purchase a spyware account and log into it.}
%% \geoff{still cryptic :-) \sumanth{Reworked this section. Hope its
%%     better now :)}}

\textbf{Experimental Setup.} I used two accounts for each app, one
for the attacker and the other as the targeted spyware user.  I then
recorded and replayed authenticated requests from the attacker's
account to the targeted user's account, substituting the ID of the
targeted user's account in the requests without changing authorization
tokens provided by the attacker's account (e.g., session IDs, API
keys).  I only replayed requests to our test accounts, and
made no attempt to access content belonging to any other account.

%% \sumanth{Reworked based on Damon's feedback}\damon{this need to be
%%   improved to better describe that I had two accounts and that we
%%   checked for cross-account data leakage. I should also be clear that
%%   I only probed our own accounts and I did not attempt to access any
%%   content that potentially belonged to another person's account.}

\textbf{Results.}  Only one of the apps in our study is vulnerable to
cross-account request forgery.
%% I disregarded apps which have API
%% structures with no IDs that identify users or devices, and instead
%% rely solely on session IDs for authentication and
%% identification.
%% \sumanth{Added this to tie well with results in table}
%% \geoff{I'm still not sure the distinction between ``No'' and ``--'' in
%%   the table.  does ``--'' mean that by design the app is not
%%   suscectiple to CARF?  and No means that the app's design could be
%%   susceptiple but its implementation is correct?} \sumanth{Yes, exactly!}
With TheTruthSpy, it was possible to
access all data (messages, contacts, locations, images, etc.)  in the
targeted account using a cookie provided by the attacker's account,
and simply swapping the attacker's device ID with the targeted
account's device ID in requests to TheTruthSpy server.  Furthermore,
when I registered multiple test accounts in succession, I noticed
that the device ID that TheTruthSpy assigns to a new device is a six-digit
integer which increases incrementally when new devices are registered.
%% \damon{how did I determine that it increased
%%   incrementally?}\sumanth{I see newer accounts always get assigned
%%   higher numbers which are very close by to older ones. I tested with
%%   2 accounts and found the deviceIDs were close by.}
The combination of insecure access controls across accounts and
predictable device IDs makes it possible for an attacker to retrieve
data from other accounts without needing to identify the device ID
beforehand.

%% by swapping the
%% device ID of a target account, while using valid cookies provided by
%% the first account. Furthermore, the device ID TheTruthSpy assigns to a
%% new device is a 6 digit integer which increases incrementally when new
%% devices are registered. \damon{how did I determine that it increased
%%   incrementally?}\sumanth{I see newer accounts always get assigned
%%   higher numbers which are very close by to older ones. I tested with
%%   2 accounts and found the deviceIDs were close by.} The combination
%% of insecure access controls across accounts and predictable device ID
%% makes it possible for an attacker to retrieve data from other accounts
%% without needed to know the device ID beforehand.

% \sumanth{TODO: Any other CARF in other apps?}

%\subsubsection*{Insecurity \#3: Leaking sensitive data on public server URIs}
\subsubsection*{Insecurity \#3: Unauthenticated Access to Victim Data}
%\subsubsection{Unauthenticated access to victim data}
\label{sec:leaky-urls}

%% \geoff{would be good to describe the scenario: some apps use CDNs or
%%   backend servers to store media data (do I know why? cost?), and the
%%   URLs they generate to the media data are unauthenticated.  the idea
%%   is to note the distinction between URLs to content on the app's server
%%   vs URLs to media stored on different infrastructure (which is my
%%   understanding of what's going on here, which may be wrong?)  either
%%   way, I want to give some sense/intuition for why URLs for accessing
%%   this content is different than other content stored on the spyware
%%   servers.} \sumanth{Good point! I've added this in the intro of the section below. One thing missing might be the reasoning as to why they choose to store media on different servers. Cost might be the main reason yes.)} \geoff{thanks, edited}

Many of the spyware apps use different backend infrastructure to store
and deliver media data that is distinct from the servers that
abusers use to access the app dashboard (e.g., abusers login
to the dashboard via the website domain in Table~\ref{tab:apps_selected}, but
the app may use a CDN to deliver images and videos).
This separate infrastructure
includes cloud storage (e.g., AWS S3 buckets), content distribution
networks, and other shared hosting services, all of which are
presumably cheaper to use for serving media data.
% I observed that
Some of the spyware apps are less careful about protecting the
data that they store on this hosting infrastructure, often allowing
unauthenticated access to the URLs they generate to stored media data.
Further, I observed user data stored in predictable URLs that make it
possible to access data across different accounts, protected solely
through security by obscurity and vulnerable to enumeration. Table~\ref{tab:apps_spyware_vuln} lists
the kinds of data leaked in public URLs for the apps studied. Failure
to authenticate access to user media (images, audio, etc.) using
mechanisms like cookies is a common example of this category of
vulnerability.

\textbf{Threat Model.} I assume that the attacker has knowledge of
the media upload path for the app based on studying media paths
revealed using accounts owned by the attacker.  For apps that use the
device ID in URL path components, I also assume the attacker knows
the targeted device ID.

\textbf{Experimental Setup.} To discover sensitive data leakage, we
focused primarily on URLs used to store media artifacts (images,
audio, video, etc.).  I extracted these URLs by examining the
browser-generated HTML content when accessing the dashboard in the
spyware account.  I only attempted to access media upload paths from
our test accounts, and made no attempt to access content belonging to
any other account.

%% \geoff{how did you collect URIs using the attacker's account?}
%% \sumanth{Addressed. Also added another statement to make sure I are
%%   clear that I collected media links from our own accounts}

\textbf{Results.}  Six of the apps in our study store their data in
public URLs accessible without authenticated access.  I disregarded
apps which store data in URLs that, although public, expire after a
short duration (e.g., Spyic's links to images expire after 1,800
seconds).

% I also disregard those apps which required authenticated
%(cookie-based) access to data. \geoff{not sure the distinction between
%  this case and other authenticated account access?}

Highstermobile stores its images with a URL scheme as a concatenation
of the image upload timestamp (UNIX timestamp with seconds precision)
and a double digit random number, with no other per-device ID in the
path (e.g.,
\texttt{\url{https://domain.com/path/photo_<timestamp><00-99>.png}}).
% \sumanth{\url{https://evt17.com/iphone/uploads/gallery/image/thumb/photo_<UNIXTimestamp><00-99>.png}}.
Since an attacker could plausibly iterate over a short range of
timestamps and random digits, this naming scheme makes it
straightforward for an attacker to gain unauthorized access to media
stored on the server for other accounts.

Cerberus and Spyhuman use public URLs that are a combination of device
ID and Unix timestamp
% (also Unix timestamp with seconds precision)
(e.g., \texttt{\url{https://domain.com/<DeviceID>-<timestamp>.ext}}).
While both of them require the attacker to know the device ID before
hand, an attacker could for instance obtain the device ID from data
dumps made public in breach attacks~\cite{mSpybrea38:online,
  Companyt8:online, HackerSt66:online, Cerberus12:online,
  Stalkerw59:online} or with physical access to the device.
%% \geoff{I added this, are there better scenarios?} \sumanth{Maybe also
%%   from public data dumps which have device metadata?}
Cerberus stores audio insecurely using the device IMEI as the device
ID.  Spyhuman stores both its images and audio insecurely using the
Android serial number as its device ID.  With both apps, an attacker
knowing the device ID could plausibly iterate over a short range of
timestamps to retrieve data stored on the server.

% \url{https://www.cerberusapp.com/audio/<DeviceID>-<UNIXTimestamp>.mp4}
% \url{https://dwnlnew.webdown2.com/rec/<DeviceID>/<UNIXTimestamp>/file.mp3}

Three other apps store data on servers using public URLs that rely on
security through obscurity, but they generate URLs that are neither
enumerable or predictable.  For instance, Spy24 allows WebRTC remote
streaming through a public URL based on a request ID generated by the
app, Spapp requires two alphanumeric keys to access image and audio
files on the server, and Meuspy generates unguessable URLs to
store images and audio.  Although certainly not good security
practice, the risk associated with unauthenticated access is lower
than for the other apps I discussed.

%% these three apps do not implement
%% good security practice by solely depending on security by obscurity,

%% \geoff{conclusion?  not good security
%%   practice but lower risk than the other apps?} \sumanth{Added.}

% complicated

%% Among the other 3 apps which leaked data on public server, all of them generate URIs which although public, is neither enumerable or predictable. These rely solely on Security through obscurity. \sumanth{e.g \textbf{Spy24.app} (which allows WebRTC remote streaming through a public URL based on a request ID generated by the app), \textbf{Spapp} (which requires 2 alphanumeric keys to access any image/audio on the server) and \textbf{Spylive360} (which generates complicated URLs to store images/audio)}

\subsubsection*{Insecurity \#4: Poor Data Retention Practices}
%\subsubsection{Poor data retention practices}

%% \sumanth{I rewrote this section to better explain what I had in mind.}

Some spyware apps have poor data retention practices that prevent
victim data from being deleted from the spyware servers. These data retention issues pose serious security and privacy risks~\cite{santhanam2022scraping}. A data breach could expose residual victim PII which has persisted even if, for instance, the abuser has deleted their account.

%% , in some cases because the data is either unaccessible by the abuser
%% or unassociated with any account.



%% All there of these cases involve unauthorized transmission of data which remains on the server indefinitely, and is either unaccessible by the abuser or unassociated with any account. These scenarios poses a risk if a data-breach exposes residual victim/attacker PII which has continued to persist.

%% \geoff{if I just have one app that has all of these risks, then we'll
%%   want to rework the story a bit}

%% Again, all data uploaded in both of these cases has the potential to
%% be leaked in a data breach.

%% \sumanth{I rewrote this section to better explain what I had in mind. Broadly speaking there are 3 cases here - Unassociated data sent without logging in, data sent but inaccessible without purchase, data sent after license expires or app is deleted. I've moved the part of 'delete' not actually deleting data to the end of section 4 along with the other misc stuff.}

%\geoff{who installed the app but never
%  used it?  an abuser who decided not to use it?  is this a compelling
%  risk?}

%% \geoff{do the apps provide the capability for the abuser to delete
%%   uploaded victim data via their server account?  if so, did I test
%%   to see if that data is actually deleted?  if not, there might not be
%%   time to do it for the submission, but is something to add for later} \sumanth{Yes, for apps which allowed the delete account option, I tried to see if both uploaded media and replaying endpoints to get, and have results for this}

%% Some apps send user data (like text messages, images, keylogger activity) to the spyware app servers before the abuser logs in/sets up the account. In some cases, this data is never visible to the attacker but is stored on the server. In some cases, user data (like images, audios, text messages, etc) persists even after explicitly deleting the account associated with the abuser. Further, in the event the license expires some spyware apps continue to send data to the backend servers, unaware of the expired license. This poses a particular issue if a data-breach exposes sensitive user data of victim's, who might have installed but never used the app \cite{esetandr4:online}

\textbf{Threat Model.} Data uploaded to the spyware servers and never deleted poses a long-term risk to being made public in data dumps associated with breach attacks.
%\sumanth{I'm not sure if this has a threat model because this doesn't have an attacker per say.}
% \geoff{data never deleted poses long-term risk to data breaches?} \sumanth{Added.}

\textbf{Experimental Setup.}  To discover poor data retention practices, I analyzed network traffic generated after the app license expired, but with the victim device still logged in.  I also tested
access to media on deleted accounts using their public URLs up to
seven days after deletion of the account.
%\sumanth{Added this line.}

%% Network traffic from the target device was captured and analyzed
%% before the abuser logged in and after the license expired.  Data
%% uploaded to the server was tested for persistence after the account
%% was expired.

\textbf{Results.}  Four of the apps in our study demonstrate poor data retention practices.

Consistent with its other data vulnerabilities,
TheTruthSpy also has data retention issues.
% \sumanth{Based off of reviewer C's comments, I omitted the data sent before registration result here. I now only talk about the data sent after license expiry and data retained after account deletion.}
It continues to send
data from the victim's phone (e.g., text messages, images, keylogger
activity) to its servers after the app license expires. Further, it persists some data after the abuser
deletes their spyware portal account and the data associated with it.
%
%before the abuser even sets up their account.
%The exfiltrated data is never associated with an account and thus
%cannot be deleted even after logging in to the spyware portal.
%
%% \geoff{how is the exfiltrated data associated with the account if it
%%   is sent before the account is set up?} \sumanth{Clarified}
%% \geoff{who installed the app but never used it?  an abuser who decided
%%   not to use it?  is this a compelling risk?}
%It also continues to exfiltrate data to its servers after the app license expires.
In particular, images uploaded from the victim device persist after
account deletion, and the images remained accessible through the
public URLs used to access them (Section~\ref{sec:leaky-urls}).

%% abuser does not uninstall the logged-in app \sumanth{This seems like a
%%   common scenario abusers might do} \geoff{it does.  have we
%%   systematically tested what happens across the apps when I delete
%%   the portal account but leave the app on the device?} \sumanth{TLDR - I did capture traffic for this scenario, but the results are fuzzy, so I can omit this.}

%% Similarly, the exfiltrated data continues to be uploaded even after the abuser deletes their account, but does not uninstall the logged-in app \sumanth{This seems like a common scenario abusers  might do} or even in case the app license expires. The uploaded data, even though valid, is no longer accessible by the abuser.

Spyic has a data retention issue resulting from its trial usage
model.  When installed for trial use, Spyic uploads data from the
victim device to the server.  But it only allows access to its portal
after the abuser has purchased a subscription.  If the abuser decides
not to purchase the spyware, victim data persists indefinitely on
Spyic's servers (presumably in anticipation of the spyware user
eventually deciding to pay for a license).

%% \geoff{I added this statement, is it accurate?  do I think that
%%   Spyzie will retain the data indefinitely in anticipation of someone
%%   eventually paying?}
%% \sumanth{Yes, afaik there's no option to delete
%%   data on Spyzie.io. https://spyzie.io/privacy.html says you can go do
%%   so after loggin in (but there's no option on the portal to do this)
%%   or contact them to delete your data}

%\sumanth{TODO: Mention about results in table 5 e.g for apps like Highster Mobile.}
Lastly, both Spapp and Meuspy persist data from an abuser's account after deletion. Images in particular continue to be accessible through the public URLs used to access them.
% Lastly, Highstermobile also transmits data from the victim's device to its server before the abuser has signed in to the app.

%% Some logged-in apps continue to upload data to the server, but do not allow access to the data from the web portal until the abuser has purchased a valid subscription. However, if the abuser discards the app and forgets to uninstall it, the user data continues to be uploaded to the server.

%% Some of the apps in the study provide the capability for abuser to delete the account and data associated with it. However, some spyware servers do not actually delete the data already uploaded to the server from the victim's device. In TheTruthSpy, images
%% uploaded from the victim device persisted even after deleting the abuser account, and remained accessible through the public URLs used to access them.

%% abusers might delete their account but never uninstall the app from
%% the victim device, and the app might continue to upload data even
%% though it is no longer accessible by the abuser.

%% It sends data from the victim device before the abuser registers an
%% account (and this data is never accessible), and it sends data from
%% the victim device even after deleting the abuser account.

%% I observe both types of unauthorized transmission
%% in \textbf{theTruthSPy} - data sent before registering an account (and
%% never accessible), and data sent from the registered target device
%% after deleting the abuser account. Further, the user-uploaded images
%% did persist (and accessible through their links) even after the
%% abuser's account was deleted.

%\sumanth{One thing I might have to do again, is to verify if the unauthorized transmission PRE/POST for most apps. The data collected is a bit fuzzy for this, especially when all communication is over HTTPS it's hard to know if the app is transmitting unauthorized data or not}

%% \geoff{conclusions and implications?  victim data remains on spyware
%%   servers indefinitely, e.g., further exposing it to breaches?} \sumanth{Added in intro to this insecurity.}

\subsubsection*{Insecurity \#5: Unauthenticated SMS Commands}
%\subsubsection{Unauthenticated SMS commands}

Four of the spyware apps I studied accept commands in
the form of SMS messages.  This capability enables the abuser to
control the spyware app on the victim device even if it is
disconnected from the Internet, or as a secondary form of control to
the web portal accessible via the abuser's account.
%% \footnote{After Android 4.4, a third-party app can no intercept and delete SMS, and prevent it from being displayed in the chat \cite{SMSInterceptAndroidKitkat:online}.
%\geoff{if I mention this in the reverse-engineering section, then I can refer back to it there} \sumanth{Modified}
%\sumanth{This seems a bit out of context here. I vote to omit it}
%}

\textbf{Threat Model.} I assume that the attacker knows the phone
number of the target device (or can enumerate it). I also assume that
the attacker knows the list of commands available by referencing online
app documentation for SMS commands, such as~\cite{SpappSMSCommands:online,
  FlexispySMSCommands:online}.
%% \sumanth{I removed the password
%%   knowledge requirement. And added another assumption about the
%%   attacker's knowledge of available SMS commands}
%\damon{Can the attacker just log into the backend website if they know the password? I might have to pair back this attacker's knowledge.} \sumanth{Good point. I believe I can assume only that the attacker knows the phone number and nothing else.}

\textbf{Experimental Setup.}
% The spyware apps that support this capability provide a list of SMS commands on their website \cite{SpappSMSCommands:online, FlexispySMSCommands:online}.
%% \geoff{if an app has a list openly accessible, I could ref a URL to a
%%   page; a reader might be curious to see what the commands look
%%   like}.\sumanth{Added this in the Threat model section.}
For each app, I systematically tested their SMS commands on our test
device, focusing in particular on their method of authenticating commands. 
%, and execute the action after authentication.
%\sumanth{Added this line}

\textbf{Results.}  Two of the four apps that accept SMS commands
require a strong password or license key to authenticate SMS commands,
and so I disregarded them from further analysis.
The remaining two apps fail to check if the text message is from an
authorized sender, and execute the commands regardless.

% I commented this out since it didn't look like it referred
% specifically to the two apps discussed in our results (GV)
%% (some apps even execute the commands after the app license has
%% expired~\cite{esetandr4:online}).

%% \sumanth{Thanks folks! I realized I don't have 5 apps anymore and jut 4 - since I removed Talklog. Which means the other two apps which I have discarded are Cerberus and FlexiSpy - both of these require a password or a license key for authenticating their SMS messages. I moved this down to results and tweaked the above statements.}

% \grant{This last sentence seems to contradict the results section below, which states that only two apps are vulnerable to the attack?}
% \geoff{I think it should be two as well...Sumanth, can you confirm?}

Spapp executes highly-sensitive SMS commands, such as remotely wiping
the victim's phone, effectively unauthenticated.  During app setup,
the app generates a random two-digit number that serves as a passcode,
and only allows SMS commands that include the correct passcode to
execute on the device.  However, this simple passcode provides little
security since a methodical attacker can send redundant commands
enumerating all possible passcodes.

Mobile-tracker-free authenticates its SMS commands, but uses a default
constant as its password.  Unless the abuser explicitly changes this
SMS password, an attacker can successfully send commands using the
default.  However, the set of commands it supports via SMS is more
restricted than Spapp (e.g., the
command \texttt{MobileTrackerFreeSMS--getlocation}
returns device location information in an SMS response).

%Cerberus authenticates the SMS message and requires a
%plain-text password to be present in every SMS
%command (the password used to authenticate SMS message is the
%same one used to log into the abuser's Cerberus web portal). Similarly, Flexispy requires the license key of the abuser's account to be present in the SMS command.
%\geoff{did not edit since I might drop the ones requiring effective
%	passwords}

%% Among the apps which receive SMS commands, \textbf{Cerberus} authenticates the SMS message and requires a password (in plain text) to be present as the prefix of every SMS command. Further, the password used to authenticate SMS message is the same one used to log into the abuser's Cerberus web portal. Unlike Cerberus, \textbf{Spapp} doesn't authenticate the SMS commands it receives, and executes them regardless. The app allows highly sensitive SMS commands- like remote wiping the target phone - to execute unauthenticated. During app setup, the app appends a random 2 digit number at the end of each SMS command (\sumanth{maybe to offer some security?}), but this is not a viable solution to thwart a dedicated attacker. Much like Cerberus, \textbf{Mobile-tracker-free} authenticates its SMS commands, but uses a default constant as its password (which isn't changed unless done so explicitly by the user). However, the list of commands it provides is more restricted (e.g MobileTrackerFreeSMS--getlocation to get target device location information), and it doesn't allow execution of powerful commands like Spapp.

%\sumanth{An attacker can go through the phone number space and ping numbers to identify which device has the app installed based off its response. How can I add this?}
%\geoff{the second part (which device has the app installed)  seems a separate topic from Spapp sending SMS responses?}

%% \sumanth{Where should the below paragraph go?}
%% \geoff{I don't see a good place for the default password issue,
%%   so my suggestion is that I comment it out.  the one place
%%   where it might find a home is as an aside at the end of the results
%%   for CARF, but it would be a tangent.}

%% Three of the apps I studied generate weak default passwords for
%% abuser accounts.  If the abuser does not change the default password,
%% their account remains susceptible to brute-force attacks by a
%% determined attacker seeking to gain access.
%% %% \geoff{is this fundamental (all FlexiSpy passwords can only be six
%% %%   digits), or just an artifact of the default (the abuser can = the
%% %%   password to a much longer one)?} \sumanth{This is just an artifact
%% %%   of the default password.}
%% The Flexispy default password is just a 6-digit number.  The
%% iKeyMonitor default password is an 8-character string, with the first 7
%% characters being numbers and the last an alphabetic character.  The
%% Highstermobile default password is an 8-character alphanumeric string
%% containing lowercase letters.

%% \sumanth{Should I talk more about this? Check if they are
%%   brute-forceable, if the API has rate limiting? Max-retry policy?
%%   etc?}

%% Around 3 of the apps I studied generated weak/poor default passwords
%% for abuser accounts. These credentials are make it easy for an
%% attacker to break into and gain access to. \textbf{FlexiSpy} default
%% password is a just a 6 digit number. \textbf{iKeyMonitor} default
%% password is a 8 character string with the first 7 characters being
%% numbers and the last an alphabet. \textbf{Highster Mobile} default
%% password is an 8 character alphanumeric string containing lowercase
%% letters and numbers. \sumanth{Should I talk more about this? Check if
%%   they are brute-forceable, if the API has rate limiting? Max-retry
%%   policy? etc?}

%For one of the apps I studied, it was possible to access all of its
%features without payment.  Due to improper access control checks,
%one can can get around the payment restriction enforced by Spyzie.io (and all the apps belonging to its family).
%Spyzie.io doesn't display the abuser's web portal until the abuser has purchased a license. However, by creating a trial account and calling the endpoints (previously documented when using the premium account) to fetch the uploaded data from the server (like sms, location, etc), the accurate data is returned. This implies that while Spyzie.io denies access to the web portal until the abuser has purchased a license, their API endpoints do no such verification checks. It might thus be possible to create a mock website calling all of spyzie's endpoints to recreate the its dashboard. \geoff{not sure what
%  you mean here, can you describe a bit more?} \sumanth{Explained in detail}
%\geoff{ok...the complexity here may not be worth trying to explain it, and
 % I haven't even described the privacy risk (data uploaded via the trial
%cannot be deleted?  or does Spyzie have reasonable delete policies?)}

%\subsection{Discussion}
\subsection{Disclosure}
\label{sec:disclosure}

We disclosed the findings in this section to all the affected
vendors on June 14th, 2022. No vendor has replied to our disclosures as of the date of
publication (three months after our disclosure).
